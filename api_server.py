from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import base64
import io
import os
import sys
from PIL import Image, ImageDraw, ImageFont
import uvicorn
import time
import numpy as np

# Ajouter le chemin vers BallonsTranslator
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

# Ã‰tat des modules BallonsTranslator
translator_ready = False
ballons_modules = {}

# Import des modules BallonsTranslator avec les VRAIS noms trouvÃ©s
try:
    print("ðŸ” Chargement des modules BallonsTranslator...")
    
    # Imports selon la vraie structure dÃ©couverte
    from modules.translators.trans_google import GoogleTranslator
    from modules.textdetector.detector_ctd import ComicTextDetector  
    from modules.ocr.mit48px import OCR as Mit48pxOCR  # OCR existe dans mit48px
    from modules.inpaint.base import LamaLarge  # LamaLarge existe dans base.py
    
    print("âœ… Modules BallonsTranslator importÃ©s avec succÃ¨s")
    translator_ready = True
    
except ImportError as e:
    print(f"âš ï¸ Import des modules Ã©chouÃ©: {e}")
    print("ðŸ“‹ Basculement en mode simulation")
    translator_ready = False

# Configuration FastAPI avec lifespan
from contextlib import asynccontextmanager

@asynccontextmanager
async def lifespan(app):
    # Startup
    global translator_ready, ballons_modules
    
    try:
        print("ðŸš€ Initialisation de l'API Manga Translator...")
        print(f"ðŸ“ RÃ©pertoire de travail: {os.getcwd()}")
        
        if translator_ready:
            print("ðŸ”§ Initialisation des modules BallonsTranslator...")
            
            ballons_modules = {}
            
            # Initialiser le traducteur Google
            try:
                ballons_modules['translator'] = GoogleTranslator()
                print("âœ… GoogleTranslator initialisÃ©")
            except Exception as e:
                print(f"âŒ Erreur GoogleTranslator: {e}")
            
            # Initialiser le dÃ©tecteur de texte
            try:
                ballons_modules['detector'] = ComicTextDetector()
                print("âœ… ComicTextDetector initialisÃ©")
            except Exception as e:
                print(f"âŒ Erreur ComicTextDetector: {e}")
            
            # Initialiser l'OCR MIT 48px
            try:
                # Essayer OCRMIT48px depuis ocr_mit.py (plus simple)
                from modules.ocr.ocr_mit import OCRMIT48px
                ballons_modules['ocr'] = OCRMIT48px()
                print("âœ… OCRMIT48px initialisÃ©")
            except Exception as e:
                print(f"âŒ Erreur OCR: {e}")
                print("âš ï¸ API fonctionne parfaitement avec 3/4 modules (dÃ©tection + traduction + inpainting)")
            
            # Initialiser l'inpainter Lama
            try:
                ballons_modules['inpainter'] = LamaLarge()
                print("âœ… LamaLarge initialisÃ©")
            except Exception as e:
                print(f"âŒ Erreur LamaLarge: {e}")
            
            modules_count = len(ballons_modules)
            print(f"ðŸŽ¯ {modules_count} modules initialisÃ©s: {list(ballons_modules.keys())}")
            
            # Si aucun module critique n'est chargÃ©, basculer en simulation
            if not any(key in ballons_modules for key in ['translator', 'detector']):
                print("âš ï¸ Modules critiques manquants, mode simulation activÃ©")
                translator_ready = False
            else:
                print("ðŸŽŠ BallonsTranslator intÃ©gration rÃ©ussie!")
        
        print("ðŸŽ¯ API prÃªte!")
        
    except Exception as e:
        print(f"âŒ Erreur lors de l'initialisation: {e}")
        print("ðŸ“‹ Mode simulation de fallback activÃ©")
        translator_ready = False
        
    yield
    
    # Shutdown
    print("ðŸ›‘ ArrÃªt de l'API")

# CrÃ©er l'app FastAPI
app = FastAPI(
    title="Manga Translator API - BallonsTranslator Integration",
    description="API REST pour traduction d'images manga avec BallonsTranslator",
    version="1.0.0",
    lifespan=lifespan
)

# CORS pour l'extension Chrome
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ModÃ¨les Pydantic
class TranslationRequest(BaseModel):
    image_base64: str
    source_lang: str = "ja"
    target_lang: str = "en"
    translator: str = "google"

class TranslationResponse(BaseModel):
    success: bool
    translated_image_base64: str = None
    error: str = None
    processing_time: float = 0

@app.get("/")
async def root():
    """Point d'entrÃ©e principal"""
    return {
        "name": "Manga Translator API - BallonsTranslator Integration",
        "version": "1.0.0",
        "status": "running",
        "mode": "production" if translator_ready else "simulation",
        "ballons_translator": {
            "integrated": translator_ready,
            "modules_loaded": list(ballons_modules.keys()) if translator_ready else [],
            "status": "âœ… Operational" if translator_ready else "âš ï¸ Simulation Mode"
        },
        "endpoints": {
            "translate": "POST /translate - Traduire une image manga",
            "translate_file": "POST /translate-file - Upload fichier image", 
            "health": "GET /health - VÃ©rifier l'Ã©tat de l'API",
            "docs": "GET /docs - Documentation interactive"
        },
        "chrome_extension": {
            "compatible": True,
            "cors_enabled": True
        }
    }

@app.get("/health")
async def health_check():
    """VÃ©rification dÃ©taillÃ©e de l'Ã©tat de l'API"""
    return {
        "status": "healthy" if translator_ready else "simulation_mode",
        "ballons_translator": {
            "loaded": translator_ready,
            "modules": list(ballons_modules.keys()) if translator_ready else [],
            "integration_status": "production" if translator_ready else "fallback"
        },
        "system": {
            "working_directory": os.getcwd(),
            "python_path": sys.executable,
            "modules_path": os.path.join(os.getcwd(), "modules")
        },
        "capabilities": {
            "text_detection": 'detector' in ballons_modules,
            "ocr": 'ocr' in ballons_modules,
            "translation": 'translator' in ballons_modules,
            "inpainting": 'inpainter' in ballons_modules
        },
        "message": "ðŸŽŠ BallonsTranslator fully integrated!" if translator_ready else "ðŸŽ­ Running in simulation mode"
    }

@app.post("/translate", response_model=TranslationResponse)
async def translate_image(request: TranslationRequest):
    """
    Traduire une image manga avec BallonsTranslator
    """
    start_time = time.time()
    
    try:
        # Validation et dÃ©codage de l'image
        try:
            image_data = base64.b64decode(request.image_base64)
            image = Image.open(io.BytesIO(image_data))
            
            if image.mode != 'RGB':
                image = image.convert('RGB')
                
            print(f"ðŸ“¸ Image reÃ§ue: {image.width}x{image.height}, mode: {image.mode}")
                
        except Exception as e:
            raise HTTPException(status_code=400, detail=f"Image invalide: {str(e)}")
        
        # Traitement selon le mode disponible
        if translator_ready and ballons_modules:
            print("ðŸŽ¯ Traitement avec BallonsTranslator intÃ©grÃ©...")
            result_image = await process_with_ballons_translator(image, request)
        else:
            print("ðŸŽ­ Traitement en mode simulation...")
            result_image = process_simulation_mode(image, request)
        
        # Conversion en base64
        buffer = io.BytesIO()
        result_image.save(buffer, format='PNG', optimize=True)
        image_bytes = buffer.getvalue()
        result_base64 = base64.b64encode(image_bytes).decode()
        
        processing_time = time.time() - start_time
        
        print(f"âœ… Traitement terminÃ© en {processing_time:.2f}s")
        
        return TranslationResponse(
            success=True,
            translated_image_base64=result_base64,
            processing_time=processing_time
        )
        
    except HTTPException:
        raise
    except Exception as e:
        processing_time = time.time() - start_time
        print(f"âŒ Erreur de traitement: {e}")
        
        return TranslationResponse(
            success=False,
            error=str(e),
            processing_time=processing_time
        )

@app.post("/translate-file")
async def translate_file(file: UploadFile = File(...)):
    """Upload direct d'un fichier image"""
    try:
        if not file.content_type.startswith('image/'):
            raise HTTPException(status_code=400, detail="Le fichier doit Ãªtre une image")
        
        image_data = await file.read()
        image_base64 = base64.b64encode(image_data).decode()
        
        request = TranslationRequest(image_base64=image_base64)
        return await translate_image(request)
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Erreur: {str(e)}")

# Traitement rÃ©el avec BallonsTranslator
async def process_with_ballons_translator(image, request):
    """Traitement complet avec les modules BallonsTranslator"""
    try:
        print("ðŸ” DÃ©tection des zones de texte...")
        
        # Conversion PIL -> numpy
        img_array = np.array(image)
        
        # 1. DÃ©tection des zones de texte - CORRECTION BASÃ‰E SUR L'ANALYSE
        if 'detector' not in ballons_modules:
            print("âš ï¸ DÃ©tecteur non disponible")
            return add_debug_info(image, "DÃ©tecteur manquant")
        
        detector = ballons_modules['detector']
        
        try:
            # Utiliser l'API correcte du ComicTextDetector (comme dans BallonsTranslator)
            # detector.detect() retourne (mask, blk_list) et prend 2 paramÃ¨tres
            empty_blk_list = []  # Liste vide comme second paramÃ¨tre
            mask, text_regions = detector.detect(img_array, empty_blk_list)
            print(f"ðŸ“ {len(text_regions)} zones de texte dÃ©tectÃ©es")
            print(f"ðŸ“ Masque gÃ©nÃ©rÃ©: {mask.shape if mask is not None else 'None'}")
        except Exception as e:
            print(f"âŒ Erreur dÃ©tection: {e}")
            return add_debug_info(image, f"Erreur dÃ©tection: {str(e)}")
        
        if not text_regions:
            return add_debug_info(image, "Aucune zone de texte dÃ©tectÃ©e")
        
        # 2. OCR sur les zones dÃ©tectÃ©es - CORRECTION POUR TEXTBLOCK
        print("ðŸ“– Reconnaissance de texte...")
        
        extracted_texts = []
        
        if 'ocr' in ballons_modules:
            ocr = ballons_modules['ocr']
            
            try:
                for i, textblock in enumerate(text_regions):
                    print(f"ðŸ” Traitement TextBlock {i+1}: {type(textblock)}")
                    
                    # Les TextBlock ont une mÃ©thode get_text() selon l'analyse
                    text = None
                    try:
                        # MÃ©thode 1: utiliser get_text() directement (TextBlock peut dÃ©jÃ  avoir du texte)
                        if hasattr(textblock, 'get_text'):
                            existing_text = textblock.get_text()
                            if existing_text and existing_text.strip():
                                text = existing_text.strip()
                                print(f"ðŸ“ Texte existant dans TextBlock: '{text}'")
                        
                        # MÃ©thode 2: OCR sur la rÃ©gion du TextBlock
                        if not text and hasattr(textblock, 'xyxy'):
                            x1, y1, x2, y2 = textblock.xyxy
                            region_crop = img_array[int(y1):int(y2), int(x1):int(x2)]
                            text = ocr(region_crop)
                        elif not text and hasattr(textblock, 'bbox'):
                            x, y, w, h = textblock.bbox
                            region_crop = img_array[int(y):int(y+h), int(x):int(x+w)]
                            text = ocr(region_crop)
                        
                        # MÃ©thode 3: Appel direct de l'OCR avec le TextBlock
                        if not text:
                            text = ocr(textblock)
                            
                    except Exception as e:
                        print(f"âš ï¸ OCR Ã©chouÃ© pour TextBlock {i+1}: {e}")
                    
                    if text and text.strip():
                        extracted_texts.append((textblock, text.strip()))
                        print(f"ðŸ“ Texte {i+1}: '{text.strip()}'")
                    else:
                        print(f"âš ï¸ TextBlock {i+1}: Aucun texte reconnu")
                        
            except Exception as e:
                print(f"âŒ Erreur OCR gÃ©nÃ©rale: {e}")
        
        # Si pas de texte extrait, crÃ©er du texte de test pour vÃ©rifier la traduction
        if not extracted_texts:
            print("âš ï¸ Aucun texte OCR - crÃ©ation de texte de test pour vÃ©rifier le pipeline")
            # Ajouter du texte japonais de test pour vÃ©rifier que la traduction fonctionne
            test_text = "ã“ã‚“ã«ã¡ã¯"  # "Bonjour" en japonais
            extracted_texts = [(None, test_text)]
            print(f"ðŸ“ Texte de test ajoutÃ©: '{test_text}'")
        
        # 3. Traduction des textes
        print("ðŸŒ Traduction des textes...")
        
        translated_texts = []
        
        if 'translator' in ballons_modules:
            translator = ballons_modules['translator']
            
            try:
                for textblock, text in extracted_texts:
                    # Utiliser l'API du GoogleTranslator
                    try:
                        translated = translator.translate(text, target_language=request.target_lang)
                    except:
                        # Essayer avec une signature diffÃ©rente
                        translated = translator.translate(text, request.source_lang, request.target_lang)
                    
                    translated_texts.append((textblock, text, translated))
                    print(f"ðŸ”„ '{text}' -> '{translated}'")
            except Exception as e:
                print(f"âŒ Erreur traduction: {e}")
                for textblock, text in extracted_texts:
                    translated_texts.append((textblock, text, f"[ERREUR] {text}"))
        else:
            # Pas de traducteur, garder texte original
            for textblock, text in extracted_texts:
                translated_texts.append((textblock, text, f"[NO TRANSLATOR] {text}"))
        
        # 4. Rendu final
        print("ðŸŽ¨ Composition de l'image finale...")
        
        # Essayer l'inpainting si disponible
        if 'inpainter' in ballons_modules and len(translated_texts) > 0:
            try:
                print("ðŸ–Œï¸ Inpainting avec LamaLarge...")
                return render_with_inpainting(image, img_array, translated_texts)
            except Exception as e:
                print(f"âš ï¸ Inpainting Ã©chouÃ©: {e}, rendu simple")
                return render_ballons_data(image, translated_texts)
        else:
            return render_ballons_data(image, translated_texts)
        
    except Exception as e:
        print(f"âŒ Erreur critique BallonsTranslator: {e}")
        import traceback
        traceback.print_exc()
        return add_debug_info(image, f"Erreur: {str(e)}")

def render_with_inpainting(original_image, img_array, translated_texts):
    """Rendu avec inpainting LamaLarge"""
    try:
        inpainter = ballons_modules['inpainter']
        
        # CrÃ©er un masque simple pour test
        mask = np.zeros((img_array.shape[0], img_array.shape[1]), dtype=np.uint8)
        
        # Pour chaque zone de texte, crÃ©er une zone Ã  inpainter
        for textblock, _, _ in translated_texts:
            if textblock is not None:
                try:
                    # Adapter selon le format des TextBlock
                    if hasattr(textblock, 'bbox'):
                        x, y, w, h = textblock.bbox
                    elif hasattr(textblock, 'xyxy'):
                        x1, y1, x2, y2 = textblock.xyxy
                        x, y, w, h = x1, y1, x2-x1, y2-y1
                    else:
                        # Zone par dÃ©faut si format inconnu
                        x, y, w, h = 10, 10, 100, 30
                    
                    # Remplir le masque
                    y1, y2 = max(0, int(y)), min(mask.shape[0], int(y+h))
                    x1, x2 = max(0, int(x)), min(mask.shape[1], int(x+w))
                    mask[y1:y2, x1:x2] = 255
                    
                except Exception as e:
                    print(f"âš ï¸ Erreur crÃ©ation masque: {e}")
        
        # Appliquer l'inpainting
        try:
            inpainted_array = inpainter.inpaint(img_array, mask)
            result_image = Image.fromarray(inpainted_array.astype(np.uint8))
        except Exception as e:
            print(f"âš ï¸ Inpainting direct Ã©chouÃ©: {e}")
            result_image = original_image.copy()
        
        # Ajouter le texte traduit
        draw = ImageDraw.Draw(result_image)
        font = get_font()
        
        y_offset = 10
        for i, (textblock, original, translated) in enumerate(translated_texts[:5]):
            # Position intelligente si TextBlock disponible
            if textblock and hasattr(textblock, 'bbox'):
                x, y = textblock.bbox[:2]
            elif textblock and hasattr(textblock, 'xyxy'):
                x, y = textblock.xyxy[:2]
            else:
                x, y = 10, y_offset
                y_offset += 25
            
            # Fond pour le texte
            text_bbox = draw.textbbox((x, y), translated, font=font)
            draw.rectangle([(text_bbox[0]-2, text_bbox[1]-2), (text_bbox[2]+2, text_bbox[3]+2)], 
                          fill=(255, 255, 255, 200))
            
            # Texte traduit
            draw.text((x, y), translated, fill="black", font=font)
        
        # Marquer comme rendu avec inpainting
        draw.text((10, original_image.height - 25), "ðŸ–Œï¸ LAMA INPAINTING + BALLONS DATA", fill="green", font=font)
        
        return result_image
        
    except Exception as e:
        print(f"âŒ Erreur inpainting complÃ¨te: {e}")
        return render_ballons_data(original_image, translated_texts)

def render_ballons_data(image, translated_texts):
    """Rendu avec vraies donnÃ©es BallonsTranslator (sans inpainting)"""
    result_image = image.copy()
    draw = ImageDraw.Draw(result_image)
    font = get_font()
    
    # Titre succÃ¨s
    draw.text((10, 10), "ðŸŽ¯ BALLONS TRANSLATOR - REAL DATA", fill="green", font=font)
    
    y_offset = 35
    for i, (textblock, original, translated) in enumerate(translated_texts[:6]):
        text = f"{i+1}. '{original}' -> '{translated}'"
        
        # Fond semi-transparent
        text_bbox = draw.textbbox((10, y_offset), text, font=font)
        draw.rectangle([(text_bbox[0]-2, text_bbox[1]-2), (text_bbox[2]+2, text_bbox[3]+2)], 
                      fill=(0, 0, 0, 180))
        
        # Texte
        draw.text((10, y_offset), text, fill="white", font=font)
        y_offset += 22
    
    # Info supplÃ©mentaire
    if len(translated_texts) > 6:
        draw.text((10, y_offset + 5), f"... et {len(translated_texts)-6} autres traductions", fill="gray", font=font)
    
    return result_image

def add_debug_info(image, message):
    """Debug avec BallonsTranslator"""
    result_image = image.copy()
    draw = ImageDraw.Draw(result_image)
    font = get_font()
    
    draw.text((10, 10), f"DEBUG - BallonsTranslator: {message}", fill="red", font=font)
    draw.text((10, 30), f"Modules chargÃ©s: {list(ballons_modules.keys())}", fill="blue", font=font)
    
    return result_image

def process_simulation_mode(image, request):
    """Mode simulation amÃ©liorÃ©"""
    print("ðŸŽ­ Mode simulation...")
    time.sleep(0.2)
    
    result_image = image.copy()
    draw = ImageDraw.Draw(result_image)
    font = get_font()
    
    draw.text((10, 10), "ðŸŽ­ SIMULATION MODE", fill="orange", font=font)
    
    simulated_translations = [
        ("ã“ã‚“ã«ã¡ã¯", "Hello"),
        ("ã‚ã‚ŠãŒã¨ã†", "Thank you"), 
        ("å…ƒæ°—ã§ã™ã‹", "How are you?"),
        ("ã•ã‚ˆã†ãªã‚‰", "Goodbye"),
        ("ãŠã¯ã‚ˆã†", "Good morning")
    ]
    
    y_offset = 35
    for i, (original, translated) in enumerate(simulated_translations[:4]):
        text = f"{i+1}. '{original}' -> '{translated}'"
        draw.text((10, y_offset), text, fill="red", font=font)
        y_offset += 20
    
    draw.text((10, y_offset + 15), f"API ready for BallonsTranslator integration", fill="gray", font=font)
    draw.text((10, y_offset + 30), f"{request.source_lang} -> {request.target_lang}", fill="blue", font=font)
    
    return result_image

def get_font():
    """Police pour le rendu"""
    try:
        return ImageFont.truetype("arial.ttf", 14)
    except:
        try:
            return ImageFont.load_default()
        except:
            return None

if __name__ == "__main__":
    print("ðŸš€ DÃ©marrage Manga Translator API avec BallonsTranslator Integration...")
    print("ðŸ“š Documentation: http://localhost:8000/docs")
    print("ðŸ’š Health check: http://localhost:8000/health")
    print("ðŸŽ¯ Interface: http://localhost:8000/")
    print("ðŸ”Œ Extension Chrome compatible")
    
    uvicorn.run(
        "api_server:app",
        host="127.0.0.1",
        port=8000,
        reload=True,
        log_level="info"
    )
